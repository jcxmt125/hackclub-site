<!DOCTYPE html>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Documentation for multi-llm series of scripts">
    <html lang="EN">

    
        <head>
        <title>Documentation for MultuLLM</title>
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans+KR:wght@300&display=swap" rel="stylesheet">
        <link href="/style.css" rel="stylesheet">
        </head>
        <body>

            <h1>Documentation for multi-llm series of scripts</h1>

            <h2>Source code</h2>

            <p>
              <a class="extLink" href="https://github.com/jcxmt125/side-projects/blob/main/python%20scripts/multillm.py">multillm.py</a><br>
              <a class="extLink" href="https://github.com/jcxmt125/side-projects/blob/main/python%20scripts/llm-comparison.py">llm-comparison.py</a><br>
            </p>

            <h2>Environment configuration</h2>

            <p>
              This project requires additional modules.<br>
              <ul>
                <li>google-generativeai</li>
                <li>python-dotenv</li>
              </ul>
            </p>

            <p>
              This script requires a .env file:<br>
              Cloudflare related:
              <ul>
                  <li>CLOUDFLARE_AI_API_KEY: an API key with access to Cloudflare's Workers AI.</li>
                  <li>CLOUDFLARE_AI_GATEWAY_SLUG: the slug you set for Cloudflare's AI gateway.</li>
                  <li>CLOUDFLARE_USER_ID: Your Cloudflare user ID: the string of letters and numbers after "dash.cloudflare.com" when logged in.</li>
              </ul>
              Other:
              <ul>
                <li>GEMINI_API_KEY: Google Gemini API key</li>
              </ul>
            </p>

            <h2>Usage instructions</h2>

            <p>
              In a terminal: execute the Python file.<br>
              For multillm, ask away, then return empty to see who you were talking to.<br>
              For llm-comparison, ask to see responses for all of the AI models. They all have seperate memories.<br>
            </p>

            <p>
              The scripts can be modified to change the used models to your liking.<br>
            </p>


        </body>
    </html>